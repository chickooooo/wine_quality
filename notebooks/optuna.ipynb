{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.073</td>\n",
       "      <td>30.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.99572</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.77</td>\n",
       "      <td>12.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.73</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>30.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99854</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.67</td>\n",
       "      <td>12.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.059</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.99660</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.73</td>\n",
       "      <td>11.3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.084</td>\n",
       "      <td>11.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.99730</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.079</td>\n",
       "      <td>10.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.99444</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.36</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "0   0            8.0              0.50         0.39             2.2   \n",
       "1   1            9.3              0.30         0.73             2.3   \n",
       "2   2            7.1              0.51         0.03             2.1   \n",
       "3   3            8.1              0.87         0.22             2.6   \n",
       "4   4            8.5              0.36         0.30             2.3   \n",
       "\n",
       "   chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  \\\n",
       "0      0.073                 30.0                  39.0  0.99572  3.33   \n",
       "1      0.092                 30.0                  67.0  0.99854  3.32   \n",
       "2      0.059                  3.0                  12.0  0.99660  3.52   \n",
       "3      0.084                 11.0                  65.0  0.99730  3.20   \n",
       "4      0.079                 10.0                  45.0  0.99444  3.20   \n",
       "\n",
       "   sulphates  alcohol  quality  \n",
       "0       0.77     12.1        6  \n",
       "1       0.67     12.8        6  \n",
       "2       0.73     11.3        7  \n",
       "3       0.53      9.8        5  \n",
       "4       1.36      9.5        6  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training data\n",
    "train_data = pd.read_csv(\"../data/train.csv\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2056</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.077</td>\n",
       "      <td>31.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99748</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.59</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2057</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.102</td>\n",
       "      <td>14.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.99586</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.68</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2058</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.065</td>\n",
       "      <td>21.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.99774</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.056</td>\n",
       "      <td>14.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.99480</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.65</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2060</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.044</td>\n",
       "      <td>8.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.99356</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.48</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "0  2056            7.2             0.510         0.01             2.0   \n",
       "1  2057            7.2             0.755         0.15             2.0   \n",
       "2  2058            8.4             0.460         0.40             2.0   \n",
       "3  2059            8.0             0.470         0.40             1.8   \n",
       "4  2060            6.5             0.340         0.32             2.1   \n",
       "\n",
       "   chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  \\\n",
       "0      0.077                 31.0                  54.0  0.99748  3.39   \n",
       "1      0.102                 14.0                  35.0  0.99586  3.33   \n",
       "2      0.065                 21.0                  50.0  0.99774  3.08   \n",
       "3      0.056                 14.0                  25.0  0.99480  3.30   \n",
       "4      0.044                  8.0                  94.0  0.99356  3.23   \n",
       "\n",
       "   sulphates  alcohol  \n",
       "0       0.59      9.8  \n",
       "1       0.68     10.0  \n",
       "2       0.65      9.5  \n",
       "3       0.65     11.7  \n",
       "4       0.48     12.8  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data\n",
    "test_data = pd.read_csv(\"../data/test.csv\")\n",
    "test_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new features\n",
    "train_data['total_acid'] = train_data['fixed acidity'] + train_data['volatile acidity'] + train_data['citric acid']\n",
    "train_data['acid/density'] = train_data['total_acid']  / train_data['density']\n",
    "train_data['alcohol_density'] = train_data['alcohol']  * train_data['density']\n",
    "train_data['sulphate/density'] = train_data['sulphates']  / train_data['density']\n",
    "train_data['sulphates/acid'] = train_data['sulphates'] / train_data['volatile acidity']\n",
    "train_data['sulphates/chlorides'] = train_data['sulphates'] / train_data['chlorides']\n",
    "train_data['sulphates*alcohol'] = train_data['sulphates'] / train_data['alcohol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>total_acid</th>\n",
       "      <th>acid/density</th>\n",
       "      <th>alcohol_density</th>\n",
       "      <th>sulphate/density</th>\n",
       "      <th>sulphates/acid</th>\n",
       "      <th>sulphates/chlorides</th>\n",
       "      <th>sulphates*alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.073</td>\n",
       "      <td>30.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.99572</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.77</td>\n",
       "      <td>12.1</td>\n",
       "      <td>6</td>\n",
       "      <td>8.89</td>\n",
       "      <td>8.928213</td>\n",
       "      <td>12.048212</td>\n",
       "      <td>0.773310</td>\n",
       "      <td>1.540000</td>\n",
       "      <td>10.547945</td>\n",
       "      <td>0.063636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.73</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>30.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99854</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.67</td>\n",
       "      <td>12.8</td>\n",
       "      <td>6</td>\n",
       "      <td>10.33</td>\n",
       "      <td>10.345104</td>\n",
       "      <td>12.781312</td>\n",
       "      <td>0.670980</td>\n",
       "      <td>2.233333</td>\n",
       "      <td>7.282609</td>\n",
       "      <td>0.052344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.059</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.99660</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.73</td>\n",
       "      <td>11.3</td>\n",
       "      <td>7</td>\n",
       "      <td>7.64</td>\n",
       "      <td>7.666065</td>\n",
       "      <td>11.261580</td>\n",
       "      <td>0.732490</td>\n",
       "      <td>1.431373</td>\n",
       "      <td>12.372881</td>\n",
       "      <td>0.064602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.084</td>\n",
       "      <td>11.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.99730</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>9.19</td>\n",
       "      <td>9.214880</td>\n",
       "      <td>9.773540</td>\n",
       "      <td>0.531435</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>6.309524</td>\n",
       "      <td>0.054082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.079</td>\n",
       "      <td>10.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.99444</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.36</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "      <td>9.16</td>\n",
       "      <td>9.211214</td>\n",
       "      <td>9.447180</td>\n",
       "      <td>1.367604</td>\n",
       "      <td>3.777778</td>\n",
       "      <td>17.215190</td>\n",
       "      <td>0.143158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "0   0            8.0              0.50         0.39             2.2   \n",
       "1   1            9.3              0.30         0.73             2.3   \n",
       "2   2            7.1              0.51         0.03             2.1   \n",
       "3   3            8.1              0.87         0.22             2.6   \n",
       "4   4            8.5              0.36         0.30             2.3   \n",
       "\n",
       "   chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  \\\n",
       "0      0.073                 30.0                  39.0  0.99572  3.33   \n",
       "1      0.092                 30.0                  67.0  0.99854  3.32   \n",
       "2      0.059                  3.0                  12.0  0.99660  3.52   \n",
       "3      0.084                 11.0                  65.0  0.99730  3.20   \n",
       "4      0.079                 10.0                  45.0  0.99444  3.20   \n",
       "\n",
       "   sulphates  alcohol  quality  total_acid  acid/density  alcohol_density  \\\n",
       "0       0.77     12.1        6        8.89      8.928213        12.048212   \n",
       "1       0.67     12.8        6       10.33     10.345104        12.781312   \n",
       "2       0.73     11.3        7        7.64      7.666065        11.261580   \n",
       "3       0.53      9.8        5        9.19      9.214880         9.773540   \n",
       "4       1.36      9.5        6        9.16      9.211214         9.447180   \n",
       "\n",
       "   sulphate/density  sulphates/acid  sulphates/chlorides  sulphates*alcohol  \n",
       "0          0.773310        1.540000            10.547945           0.063636  \n",
       "1          0.670980        2.233333             7.282609           0.052344  \n",
       "2          0.732490        1.431373            12.372881           0.064602  \n",
       "3          0.531435        0.609195             6.309524           0.054082  \n",
       "4          1.367604        3.777778            17.215190           0.143158  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspecting updated data\n",
    "train_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating scaler\n",
    "scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>total_acid</th>\n",
       "      <th>acid/density</th>\n",
       "      <th>alcohol_density</th>\n",
       "      <th>sulphate/density</th>\n",
       "      <th>sulphates/acid</th>\n",
       "      <th>sulphates/chlorides</th>\n",
       "      <th>sulphates*alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.073</td>\n",
       "      <td>30.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.99572</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.77</td>\n",
       "      <td>12.1</td>\n",
       "      <td>8.89</td>\n",
       "      <td>8.928213</td>\n",
       "      <td>12.048212</td>\n",
       "      <td>0.773310</td>\n",
       "      <td>1.540000</td>\n",
       "      <td>10.547945</td>\n",
       "      <td>0.063636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.73</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>30.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99854</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.67</td>\n",
       "      <td>12.8</td>\n",
       "      <td>10.33</td>\n",
       "      <td>10.345104</td>\n",
       "      <td>12.781312</td>\n",
       "      <td>0.670980</td>\n",
       "      <td>2.233333</td>\n",
       "      <td>7.282609</td>\n",
       "      <td>0.052344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.1</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.059</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.99660</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.73</td>\n",
       "      <td>11.3</td>\n",
       "      <td>7.64</td>\n",
       "      <td>7.666065</td>\n",
       "      <td>11.261580</td>\n",
       "      <td>0.732490</td>\n",
       "      <td>1.431373</td>\n",
       "      <td>12.372881</td>\n",
       "      <td>0.064602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.084</td>\n",
       "      <td>11.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.99730</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.8</td>\n",
       "      <td>9.19</td>\n",
       "      <td>9.214880</td>\n",
       "      <td>9.773540</td>\n",
       "      <td>0.531435</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>6.309524</td>\n",
       "      <td>0.054082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.5</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.079</td>\n",
       "      <td>10.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.99444</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.36</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.16</td>\n",
       "      <td>9.211214</td>\n",
       "      <td>9.447180</td>\n",
       "      <td>1.367604</td>\n",
       "      <td>3.777778</td>\n",
       "      <td>17.215190</td>\n",
       "      <td>0.143158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            8.0              0.50         0.39             2.2      0.073   \n",
       "1            9.3              0.30         0.73             2.3      0.092   \n",
       "2            7.1              0.51         0.03             2.1      0.059   \n",
       "3            8.1              0.87         0.22             2.6      0.084   \n",
       "4            8.5              0.36         0.30             2.3      0.079   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 30.0                  39.0  0.99572  3.33       0.77   \n",
       "1                 30.0                  67.0  0.99854  3.32       0.67   \n",
       "2                  3.0                  12.0  0.99660  3.52       0.73   \n",
       "3                 11.0                  65.0  0.99730  3.20       0.53   \n",
       "4                 10.0                  45.0  0.99444  3.20       1.36   \n",
       "\n",
       "   alcohol  total_acid  acid/density  alcohol_density  sulphate/density  \\\n",
       "0     12.1        8.89      8.928213        12.048212          0.773310   \n",
       "1     12.8       10.33     10.345104        12.781312          0.670980   \n",
       "2     11.3        7.64      7.666065        11.261580          0.732490   \n",
       "3      9.8        9.19      9.214880         9.773540          0.531435   \n",
       "4      9.5        9.16      9.211214         9.447180          1.367604   \n",
       "\n",
       "   sulphates/acid  sulphates/chlorides  sulphates*alcohol  \n",
       "0        1.540000            10.547945           0.063636  \n",
       "1        2.233333             7.282609           0.052344  \n",
       "2        1.431373            12.372881           0.064602  \n",
       "3        0.609195             6.309524           0.054082  \n",
       "4        3.777778            17.215190           0.143158  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing id and quality feature\n",
    "data_1 = train_data.drop(['Id', 'quality'], axis=1)\n",
    "data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>total_acid</th>\n",
       "      <th>acid/density</th>\n",
       "      <th>alcohol_density</th>\n",
       "      <th>sulphate/density</th>\n",
       "      <th>sulphates/acid</th>\n",
       "      <th>sulphates/chlorides</th>\n",
       "      <th>sulphates*alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.315789</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>-0.116279</td>\n",
       "      <td>-0.445455</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.066090</td>\n",
       "      <td>1.305148</td>\n",
       "      <td>0.951503</td>\n",
       "      <td>0.388627</td>\n",
       "      <td>0.909747</td>\n",
       "      <td>0.283881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.675</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>1.454545</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.836364</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.754808</td>\n",
       "      <td>0.746963</td>\n",
       "      <td>1.787760</td>\n",
       "      <td>0.348570</td>\n",
       "      <td>1.230653</td>\n",
       "      <td>-0.145427</td>\n",
       "      <td>-0.523106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.425</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>-1.052632</td>\n",
       "      <td>-0.8125</td>\n",
       "      <td>-0.744186</td>\n",
       "      <td>-0.045455</td>\n",
       "      <td>1.105263</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-0.538462</td>\n",
       "      <td>-0.540423</td>\n",
       "      <td>0.787294</td>\n",
       "      <td>0.710994</td>\n",
       "      <td>0.256704</td>\n",
       "      <td>1.499465</td>\n",
       "      <td>0.352870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.075</td>\n",
       "      <td>1.40</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>-0.3125</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>-0.578947</td>\n",
       "      <td>-0.470588</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.206731</td>\n",
       "      <td>0.203845</td>\n",
       "      <td>-0.192308</td>\n",
       "      <td>-0.473633</td>\n",
       "      <td>-0.741798</td>\n",
       "      <td>-0.459874</td>\n",
       "      <td>-0.398915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.275</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.3750</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>-1.027273</td>\n",
       "      <td>-0.578947</td>\n",
       "      <td>4.411765</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.202084</td>\n",
       "      <td>-0.407156</td>\n",
       "      <td>4.453107</td>\n",
       "      <td>3.106319</td>\n",
       "      <td>3.064228</td>\n",
       "      <td>5.966608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0          0.025             -0.08     0.424242        0.000000  -0.315789   \n",
       "1          0.675             -0.88     1.454545        0.142857   0.684211   \n",
       "2         -0.425             -0.04    -0.666667       -0.142857  -1.052632   \n",
       "3          0.075              1.40    -0.090909        0.571429   0.263158   \n",
       "4          0.275             -0.64     0.151515        0.142857   0.000000   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide   density        pH  sulphates  \\\n",
       "0               0.8750             -0.116279 -0.445455  0.105263   0.941176   \n",
       "1               0.8750              0.534884  0.836364  0.052632   0.352941   \n",
       "2              -0.8125             -0.744186 -0.045455  1.105263   0.705882   \n",
       "3              -0.3125              0.488372  0.272727 -0.578947  -0.470588   \n",
       "4              -0.3750              0.023256 -1.027273 -0.578947   4.411765   \n",
       "\n",
       "    alcohol  total_acid  acid/density  alcohol_density  sulphate/density  \\\n",
       "0  1.333333    0.062500      0.066090         1.305148          0.951503   \n",
       "1  1.800000    0.754808      0.746963         1.787760          0.348570   \n",
       "2  0.800000   -0.538462     -0.540423         0.787294          0.710994   \n",
       "3 -0.200000    0.206731      0.203845        -0.192308         -0.473633   \n",
       "4 -0.400000    0.192308      0.202084        -0.407156          4.453107   \n",
       "\n",
       "   sulphates/acid  sulphates/chlorides  sulphates*alcohol  \n",
       "0        0.388627             0.909747           0.283881  \n",
       "1        1.230653            -0.145427          -0.523106  \n",
       "2        0.256704             1.499465           0.352870  \n",
       "3       -0.741798            -0.459874          -0.398915  \n",
       "4        3.106319             3.064228           5.966608  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaling data\n",
    "train_scaled = scaler.fit_transform(data_1)\n",
    "# converting back to dataframe\n",
    "train_scaled = pd.DataFrame(train_scaled, columns=data_1.columns)\n",
    "train_scaled.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>total_acid</th>\n",
       "      <th>acid/density</th>\n",
       "      <th>alcohol_density</th>\n",
       "      <th>sulphate/density</th>\n",
       "      <th>sulphates/acid</th>\n",
       "      <th>sulphates/chlorides</th>\n",
       "      <th>sulphates*alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.073</td>\n",
       "      <td>30.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.99572</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.77</td>\n",
       "      <td>12.1</td>\n",
       "      <td>8.89</td>\n",
       "      <td>8.928213</td>\n",
       "      <td>12.048212</td>\n",
       "      <td>0.773310</td>\n",
       "      <td>1.540000</td>\n",
       "      <td>10.547945</td>\n",
       "      <td>0.063636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.73</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>30.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99854</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.67</td>\n",
       "      <td>12.8</td>\n",
       "      <td>10.33</td>\n",
       "      <td>10.345104</td>\n",
       "      <td>12.781312</td>\n",
       "      <td>0.670980</td>\n",
       "      <td>2.233333</td>\n",
       "      <td>7.282609</td>\n",
       "      <td>0.052344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.1</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.059</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.99660</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.73</td>\n",
       "      <td>11.3</td>\n",
       "      <td>7.64</td>\n",
       "      <td>7.666065</td>\n",
       "      <td>11.261580</td>\n",
       "      <td>0.732490</td>\n",
       "      <td>1.431373</td>\n",
       "      <td>12.372881</td>\n",
       "      <td>0.064602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.084</td>\n",
       "      <td>11.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.99730</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.8</td>\n",
       "      <td>9.19</td>\n",
       "      <td>9.214880</td>\n",
       "      <td>9.773540</td>\n",
       "      <td>0.531435</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>6.309524</td>\n",
       "      <td>0.054082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.5</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.079</td>\n",
       "      <td>10.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.99444</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.36</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.16</td>\n",
       "      <td>9.211214</td>\n",
       "      <td>9.447180</td>\n",
       "      <td>1.367604</td>\n",
       "      <td>3.777778</td>\n",
       "      <td>17.215190</td>\n",
       "      <td>0.143158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            8.0              0.50         0.39             2.2      0.073   \n",
       "1            9.3              0.30         0.73             2.3      0.092   \n",
       "2            7.1              0.51         0.03             2.1      0.059   \n",
       "3            8.1              0.87         0.22             2.6      0.084   \n",
       "4            8.5              0.36         0.30             2.3      0.079   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 30.0                  39.0  0.99572  3.33       0.77   \n",
       "1                 30.0                  67.0  0.99854  3.32       0.67   \n",
       "2                  3.0                  12.0  0.99660  3.52       0.73   \n",
       "3                 11.0                  65.0  0.99730  3.20       0.53   \n",
       "4                 10.0                  45.0  0.99444  3.20       1.36   \n",
       "\n",
       "   alcohol  total_acid  acid/density  alcohol_density  sulphate/density  \\\n",
       "0     12.1        8.89      8.928213        12.048212          0.773310   \n",
       "1     12.8       10.33     10.345104        12.781312          0.670980   \n",
       "2     11.3        7.64      7.666065        11.261580          0.732490   \n",
       "3      9.8        9.19      9.214880         9.773540          0.531435   \n",
       "4      9.5        9.16      9.211214         9.447180          1.367604   \n",
       "\n",
       "   sulphates/acid  sulphates/chlorides  sulphates*alcohol  \n",
       "0        1.540000            10.547945           0.063636  \n",
       "1        2.233333             7.282609           0.052344  \n",
       "2        1.431373            12.372881           0.064602  \n",
       "3        0.609195             6.309524           0.054082  \n",
       "4        3.777778            17.215190           0.143158  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating X\n",
    "X = train_data.drop(['Id', 'quality'], axis=1)\n",
    "# X = train_scaled\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   quality\n",
       "0        6\n",
       "1        6\n",
       "2        7\n",
       "3        5\n",
       "4        6"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating y\n",
    "y = train_data[['quality']]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating validation set\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=True, stratify=y.quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1644, 18)\n",
      "(412, 18)\n",
      "(1644, 1)\n",
      "(412, 1)\n"
     ]
    }
   ],
   "source": [
    "# verifying shape\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quadratic weighted kappa\n",
    "def quad_kappa(y, y_pred):\n",
    "    return cohen_kappa_score(y, y_pred, weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom scorer\n",
    "custom_scorer = make_scorer(quad_kappa, greater_is_better=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creatiing classifier\n",
    "classifier = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation scores\n",
    "scores = cross_val_score(classifier, x_train, np.ravel(y_train), cv=10, scoring=custom_scorer, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44354234, 0.48879757, 0.49597905, 0.48151087, 0.45753528,\n",
       "       0.45315463, 0.48771973, 0.47774166, 0.44348598, 0.52965585])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspecting scores\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4759122963344008"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean score\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the model\n",
    "classifier.fit(x_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alcohol_density         0.098013\n",
       "sulphate/density        0.094447\n",
       "alcohol                 0.072236\n",
       "sulphates*alcohol       0.062481\n",
       "sulphates/acid          0.059691\n",
       "density                 0.056189\n",
       "sulphates               0.056015\n",
       "total sulfur dioxide    0.055944\n",
       "sulphates/chlorides     0.050385\n",
       "pH                      0.047683\n",
       "residual sugar          0.047262\n",
       "total_acid              0.046575\n",
       "volatile acidity        0.045114\n",
       "chlorides               0.044646\n",
       "acid/density            0.043545\n",
       "free sulfur dioxide     0.041916\n",
       "citric acid             0.039512\n",
       "fixed acidity           0.038344\n",
       "dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspecting feature importance\n",
    "importance = pd.Series(classifier.feature_importances_, index=classifier.feature_names_in_)\n",
    "importance.sort_values(ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna as op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective function\n",
    "def objective(trial):\n",
    "\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 20)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "    return cross_val_score(clf, x_train, np.ravel(y_train), n_jobs=-1, cv=5, scoring=custom_scorer).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-02 16:24:19,492]\u001b[0m A new study created in memory with name: no-name-33407c3a-96fd-4346-a586-d7303eae6c3a\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:24:23,105]\u001b[0m Trial 0 finished with value: 0.4815750030809694 and parameters: {'n_estimators': 488, 'max_depth': 10, 'min_samples_split': 13}. Best is trial 0 with value: 0.4815750030809694.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:24:25,888]\u001b[0m Trial 1 finished with value: 0.4854157295469005 and parameters: {'n_estimators': 490, 'max_depth': 11, 'min_samples_split': 15}. Best is trial 1 with value: 0.4854157295469005.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:24:27,077]\u001b[0m Trial 2 finished with value: 0.49217777205350044 and parameters: {'n_estimators': 229, 'max_depth': 7, 'min_samples_split': 10}. Best is trial 2 with value: 0.49217777205350044.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:24:29,433]\u001b[0m Trial 3 finished with value: 0.4897381883143135 and parameters: {'n_estimators': 424, 'max_depth': 19, 'min_samples_split': 18}. Best is trial 2 with value: 0.49217777205350044.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:24:30,296]\u001b[0m Trial 4 finished with value: 0.475856457282246 and parameters: {'n_estimators': 153, 'max_depth': 13, 'min_samples_split': 20}. Best is trial 2 with value: 0.49217777205350044.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:24:32,227]\u001b[0m Trial 5 finished with value: 0.4869873053720494 and parameters: {'n_estimators': 360, 'max_depth': 19, 'min_samples_split': 17}. Best is trial 2 with value: 0.49217777205350044.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:24:33,069]\u001b[0m Trial 6 finished with value: 0.4854115519536128 and parameters: {'n_estimators': 153, 'max_depth': 18, 'min_samples_split': 12}. Best is trial 2 with value: 0.49217777205350044.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:24:34,355]\u001b[0m Trial 7 finished with value: 0.4262316019653339 and parameters: {'n_estimators': 337, 'max_depth': 3, 'min_samples_split': 5}. Best is trial 2 with value: 0.49217777205350044.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:24:34,922]\u001b[0m Trial 8 finished with value: 0.4840107917581138 and parameters: {'n_estimators': 107, 'max_depth': 12, 'min_samples_split': 18}. Best is trial 2 with value: 0.49217777205350044.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:24:35,632]\u001b[0m Trial 9 finished with value: 0.4817470590653715 and parameters: {'n_estimators': 147, 'max_depth': 6, 'min_samples_split': 3}. Best is trial 2 with value: 0.49217777205350044.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:24:36,526]\u001b[0m Trial 10 finished with value: 0.3697262745464337 and parameters: {'n_estimators': 257, 'max_depth': 1, 'min_samples_split': 6}. Best is trial 2 with value: 0.49217777205350044.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:24:37,813]\u001b[0m Trial 11 finished with value: 0.48667467182812835 and parameters: {'n_estimators': 256, 'max_depth': 7, 'min_samples_split': 9}. Best is trial 2 with value: 0.49217777205350044.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:24:40,225]\u001b[0m Trial 12 finished with value: 0.4800234382152386 and parameters: {'n_estimators': 415, 'max_depth': 16, 'min_samples_split': 9}. Best is trial 2 with value: 0.49217777205350044.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:24:41,418]\u001b[0m Trial 13 finished with value: 0.4871159868343956 and parameters: {'n_estimators': 238, 'max_depth': 7, 'min_samples_split': 9}. Best is trial 2 with value: 0.49217777205350044.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:24:43,795]\u001b[0m Trial 14 finished with value: 0.48406015383646056 and parameters: {'n_estimators': 415, 'max_depth': 15, 'min_samples_split': 14}. Best is trial 2 with value: 0.49217777205350044.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:24:44,624]\u001b[0m Trial 15 finished with value: 0.457888329453794 and parameters: {'n_estimators': 207, 'max_depth': 4, 'min_samples_split': 16}. Best is trial 2 with value: 0.49217777205350044.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:24:46,166]\u001b[0m Trial 16 finished with value: 0.48738079828016045 and parameters: {'n_estimators': 309, 'max_depth': 9, 'min_samples_split': 20}. Best is trial 2 with value: 0.49217777205350044.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:24:48,569]\u001b[0m Trial 17 finished with value: 0.4833106351589443 and parameters: {'n_estimators': 428, 'max_depth': 15, 'min_samples_split': 11}. Best is trial 2 with value: 0.49217777205350044.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:24:50,454]\u001b[0m Trial 18 finished with value: 0.4850455961748386 and parameters: {'n_estimators': 360, 'max_depth': 9, 'min_samples_split': 7}. Best is trial 2 with value: 0.49217777205350044.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:24:51,651]\u001b[0m Trial 19 finished with value: 0.4873269229427237 and parameters: {'n_estimators': 205, 'max_depth': 17, 'min_samples_split': 11}. Best is trial 2 with value: 0.49217777205350044.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:24:54,448]\u001b[0m Trial 20 finished with value: 0.48069266517142195 and parameters: {'n_estimators': 457, 'max_depth': 13, 'min_samples_split': 2}. Best is trial 2 with value: 0.49217777205350044.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:24:56,054]\u001b[0m Trial 21 finished with value: 0.4927545265248594 and parameters: {'n_estimators': 299, 'max_depth': 20, 'min_samples_split': 20}. Best is trial 21 with value: 0.4927545265248594.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:24:57,669]\u001b[0m Trial 22 finished with value: 0.476963381964429 and parameters: {'n_estimators': 298, 'max_depth': 20, 'min_samples_split': 18}. Best is trial 21 with value: 0.4927545265248594.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:24:59,264]\u001b[0m Trial 23 finished with value: 0.49327083308857256 and parameters: {'n_estimators': 294, 'max_depth': 19, 'min_samples_split': 19}. Best is trial 23 with value: 0.49327083308857256.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:00,842]\u001b[0m Trial 24 finished with value: 0.4865924339328001 and parameters: {'n_estimators': 288, 'max_depth': 20, 'min_samples_split': 20}. Best is trial 23 with value: 0.49327083308857256.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:01,995]\u001b[0m Trial 25 finished with value: 0.49872904586836864 and parameters: {'n_estimators': 206, 'max_depth': 17, 'min_samples_split': 16}. Best is trial 25 with value: 0.49872904586836864.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:03,042]\u001b[0m Trial 26 finished with value: 0.47894355592291504 and parameters: {'n_estimators': 186, 'max_depth': 18, 'min_samples_split': 16}. Best is trial 25 with value: 0.49872904586836864.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:04,535]\u001b[0m Trial 27 finished with value: 0.4881623193752027 and parameters: {'n_estimators': 274, 'max_depth': 16, 'min_samples_split': 19}. Best is trial 25 with value: 0.49872904586836864.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:06,382]\u001b[0m Trial 28 finished with value: 0.4866450695363616 and parameters: {'n_estimators': 323, 'max_depth': 14, 'min_samples_split': 16}. Best is trial 25 with value: 0.49872904586836864.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:08,665]\u001b[0m Trial 29 finished with value: 0.4759928067386482 and parameters: {'n_estimators': 376, 'max_depth': 18, 'min_samples_split': 13}. Best is trial 25 with value: 0.49872904586836864.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:09,848]\u001b[0m Trial 30 finished with value: 0.4849696830672334 and parameters: {'n_estimators': 186, 'max_depth': 20, 'min_samples_split': 14}. Best is trial 25 with value: 0.49872904586836864.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:11,135]\u001b[0m Trial 31 finished with value: 0.4949421318797357 and parameters: {'n_estimators': 231, 'max_depth': 17, 'min_samples_split': 19}. Best is trial 25 with value: 0.49872904586836864.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:12,872]\u001b[0m Trial 32 finished with value: 0.493400577551277 and parameters: {'n_estimators': 265, 'max_depth': 18, 'min_samples_split': 19}. Best is trial 25 with value: 0.49872904586836864.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:14,143]\u001b[0m Trial 33 finished with value: 0.49158240032073064 and parameters: {'n_estimators': 241, 'max_depth': 17, 'min_samples_split': 17}. Best is trial 25 with value: 0.49872904586836864.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:15,250]\u001b[0m Trial 34 finished with value: 0.49071946420151447 and parameters: {'n_estimators': 218, 'max_depth': 16, 'min_samples_split': 19}. Best is trial 25 with value: 0.49872904586836864.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:16,650]\u001b[0m Trial 35 finished with value: 0.4879532947198911 and parameters: {'n_estimators': 271, 'max_depth': 17, 'min_samples_split': 18}. Best is trial 25 with value: 0.49872904586836864.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:17,542]\u001b[0m Trial 36 finished with value: 0.5029443387837075 and parameters: {'n_estimators': 180, 'max_depth': 11, 'min_samples_split': 15}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:18,140]\u001b[0m Trial 37 finished with value: 0.48621566191216914 and parameters: {'n_estimators': 117, 'max_depth': 10, 'min_samples_split': 15}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:19,076]\u001b[0m Trial 38 finished with value: 0.4926946381078799 and parameters: {'n_estimators': 178, 'max_depth': 12, 'min_samples_split': 17}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:19,817]\u001b[0m Trial 39 finished with value: 0.49877946275507323 and parameters: {'n_estimators': 135, 'max_depth': 14, 'min_samples_split': 15}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:20,601]\u001b[0m Trial 40 finished with value: 0.49384652329609285 and parameters: {'n_estimators': 143, 'max_depth': 14, 'min_samples_split': 13}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:21,436]\u001b[0m Trial 41 finished with value: 0.482496106930783 and parameters: {'n_estimators': 131, 'max_depth': 14, 'min_samples_split': 13}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:22,457]\u001b[0m Trial 42 finished with value: 0.48225464569930043 and parameters: {'n_estimators': 168, 'max_depth': 11, 'min_samples_split': 15}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:23,185]\u001b[0m Trial 43 finished with value: 0.48052709136353106 and parameters: {'n_estimators': 134, 'max_depth': 13, 'min_samples_split': 14}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:24,042]\u001b[0m Trial 44 finished with value: 0.4843589164281024 and parameters: {'n_estimators': 163, 'max_depth': 12, 'min_samples_split': 12}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:24,931]\u001b[0m Trial 45 finished with value: 0.48700135782257553 and parameters: {'n_estimators': 141, 'max_depth': 14, 'min_samples_split': 12}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:26,036]\u001b[0m Trial 46 finished with value: 0.4903711685459373 and parameters: {'n_estimators': 198, 'max_depth': 15, 'min_samples_split': 15}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:26,660]\u001b[0m Trial 47 finished with value: 0.4943839275889541 and parameters: {'n_estimators': 103, 'max_depth': 12, 'min_samples_split': 16}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:27,376]\u001b[0m Trial 48 finished with value: 0.4762205216504668 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 17}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:28,015]\u001b[0m Trial 49 finished with value: 0.4891492502479231 and parameters: {'n_estimators': 118, 'max_depth': 9, 'min_samples_split': 16}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:28,995]\u001b[0m Trial 50 finished with value: 0.49353629550781963 and parameters: {'n_estimators': 164, 'max_depth': 11, 'min_samples_split': 15}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:30,424]\u001b[0m Trial 51 finished with value: 0.4909573848210629 and parameters: {'n_estimators': 225, 'max_depth': 13, 'min_samples_split': 14}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:31,346]\u001b[0m Trial 52 finished with value: 0.49520508072477654 and parameters: {'n_estimators': 146, 'max_depth': 8, 'min_samples_split': 13}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:31,988]\u001b[0m Trial 53 finished with value: 0.48447582150127716 and parameters: {'n_estimators': 120, 'max_depth': 8, 'min_samples_split': 16}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:32,780]\u001b[0m Trial 54 finished with value: 0.486048931605174 and parameters: {'n_estimators': 153, 'max_depth': 8, 'min_samples_split': 15}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:33,751]\u001b[0m Trial 55 finished with value: 0.48549462702945945 and parameters: {'n_estimators': 194, 'max_depth': 5, 'min_samples_split': 10}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:34,737]\u001b[0m Trial 56 finished with value: 0.4859695660991198 and parameters: {'n_estimators': 213, 'max_depth': 6, 'min_samples_split': 14}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:36,019]\u001b[0m Trial 57 finished with value: 0.4982306576100012 and parameters: {'n_estimators': 240, 'max_depth': 11, 'min_samples_split': 17}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:37,196]\u001b[0m Trial 58 finished with value: 0.484687507857279 and parameters: {'n_estimators': 238, 'max_depth': 8, 'min_samples_split': 17}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:38,578]\u001b[0m Trial 59 finished with value: 0.48489181424454475 and parameters: {'n_estimators': 247, 'max_depth': 11, 'min_samples_split': 17}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:39,536]\u001b[0m Trial 60 finished with value: 0.4807064496868037 and parameters: {'n_estimators': 174, 'max_depth': 15, 'min_samples_split': 18}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:40,372]\u001b[0m Trial 61 finished with value: 0.4896378261764317 and parameters: {'n_estimators': 153, 'max_depth': 12, 'min_samples_split': 16}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:41,083]\u001b[0m Trial 62 finished with value: 0.4905318665608064 and parameters: {'n_estimators': 130, 'max_depth': 10, 'min_samples_split': 18}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:41,691]\u001b[0m Trial 63 finished with value: 0.49326531367106574 and parameters: {'n_estimators': 104, 'max_depth': 12, 'min_samples_split': 13}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:42,835]\u001b[0m Trial 64 finished with value: 0.49376772866372054 and parameters: {'n_estimators': 228, 'max_depth': 9, 'min_samples_split': 17}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:43,399]\u001b[0m Trial 65 finished with value: 0.37212028473573777 and parameters: {'n_estimators': 187, 'max_depth': 1, 'min_samples_split': 14}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:44,473]\u001b[0m Trial 66 finished with value: 0.4848507764443409 and parameters: {'n_estimators': 204, 'max_depth': 11, 'min_samples_split': 11}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:45,374]\u001b[0m Trial 67 finished with value: 0.4915431292072137 and parameters: {'n_estimators': 174, 'max_depth': 13, 'min_samples_split': 19}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:46,779]\u001b[0m Trial 68 finished with value: 0.4826671981459005 and parameters: {'n_estimators': 253, 'max_depth': 16, 'min_samples_split': 15}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:47,726]\u001b[0m Trial 69 finished with value: 0.487550728574525 and parameters: {'n_estimators': 155, 'max_depth': 17, 'min_samples_split': 16}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:48,354]\u001b[0m Trial 70 finished with value: 0.48945902793874163 and parameters: {'n_estimators': 117, 'max_depth': 19, 'min_samples_split': 20}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:49,107]\u001b[0m Trial 71 finished with value: 0.4934151505878302 and parameters: {'n_estimators': 136, 'max_depth': 14, 'min_samples_split': 12}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:49,880]\u001b[0m Trial 72 finished with value: 0.49193129678835323 and parameters: {'n_estimators': 143, 'max_depth': 13, 'min_samples_split': 13}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:50,982]\u001b[0m Trial 73 finished with value: 0.4915770207869684 and parameters: {'n_estimators': 212, 'max_depth': 12, 'min_samples_split': 16}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:51,607]\u001b[0m Trial 74 finished with value: 0.4820726498444053 and parameters: {'n_estimators': 111, 'max_depth': 14, 'min_samples_split': 14}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:52,301]\u001b[0m Trial 75 finished with value: 0.4947357847731597 and parameters: {'n_estimators': 126, 'max_depth': 15, 'min_samples_split': 15}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:52,969]\u001b[0m Trial 76 finished with value: 0.4826598884018317 and parameters: {'n_estimators': 124, 'max_depth': 15, 'min_samples_split': 18}. Best is trial 36 with value: 0.5029443387837075.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:53,947]\u001b[0m Trial 77 finished with value: 0.503116707021326 and parameters: {'n_estimators': 183, 'max_depth': 16, 'min_samples_split': 16}. Best is trial 77 with value: 0.503116707021326.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:54,923]\u001b[0m Trial 78 finished with value: 0.4870032644196961 and parameters: {'n_estimators': 184, 'max_depth': 16, 'min_samples_split': 15}. Best is trial 77 with value: 0.503116707021326.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:56,077]\u001b[0m Trial 79 finished with value: 0.4908576296526787 and parameters: {'n_estimators': 220, 'max_depth': 18, 'min_samples_split': 17}. Best is trial 77 with value: 0.503116707021326.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:57,545]\u001b[0m Trial 80 finished with value: 0.4896666511424252 and parameters: {'n_estimators': 279, 'max_depth': 17, 'min_samples_split': 15}. Best is trial 77 with value: 0.503116707021326.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:58,420]\u001b[0m Trial 81 finished with value: 0.4842357072942991 and parameters: {'n_estimators': 161, 'max_depth': 15, 'min_samples_split': 16}. Best is trial 77 with value: 0.503116707021326.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:25:59,480]\u001b[0m Trial 82 finished with value: 0.48532499296594533 and parameters: {'n_estimators': 197, 'max_depth': 16, 'min_samples_split': 16}. Best is trial 77 with value: 0.503116707021326.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:26:00,350]\u001b[0m Trial 83 finished with value: 0.48697650528148684 and parameters: {'n_estimators': 146, 'max_depth': 17, 'min_samples_split': 4}. Best is trial 77 with value: 0.503116707021326.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:26:01,061]\u001b[0m Trial 84 finished with value: 0.4794960129772403 and parameters: {'n_estimators': 127, 'max_depth': 15, 'min_samples_split': 14}. Best is trial 77 with value: 0.503116707021326.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:26:02,320]\u001b[0m Trial 85 finished with value: 0.49506586759698223 and parameters: {'n_estimators': 238, 'max_depth': 19, 'min_samples_split': 17}. Best is trial 77 with value: 0.503116707021326.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:26:03,586]\u001b[0m Trial 86 finished with value: 0.4936669370824628 and parameters: {'n_estimators': 243, 'max_depth': 18, 'min_samples_split': 19}. Best is trial 77 with value: 0.503116707021326.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:26:06,134]\u001b[0m Trial 87 finished with value: 0.4877783743858915 and parameters: {'n_estimators': 499, 'max_depth': 19, 'min_samples_split': 17}. Best is trial 77 with value: 0.503116707021326.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:26:07,496]\u001b[0m Trial 88 finished with value: 0.49017807815559394 and parameters: {'n_estimators': 262, 'max_depth': 19, 'min_samples_split': 18}. Best is trial 77 with value: 0.503116707021326.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:26:08,710]\u001b[0m Trial 89 finished with value: 0.4836839467698158 and parameters: {'n_estimators': 229, 'max_depth': 18, 'min_samples_split': 15}. Best is trial 77 with value: 0.503116707021326.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:26:10,028]\u001b[0m Trial 90 finished with value: 0.48985636237600794 and parameters: {'n_estimators': 234, 'max_depth': 16, 'min_samples_split': 8}. Best is trial 77 with value: 0.503116707021326.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:26:10,622]\u001b[0m Trial 91 finished with value: 0.4841328530766239 and parameters: {'n_estimators': 109, 'max_depth': 11, 'min_samples_split': 16}. Best is trial 77 with value: 0.503116707021326.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:26:11,588]\u001b[0m Trial 92 finished with value: 0.48449524570695396 and parameters: {'n_estimators': 180, 'max_depth': 17, 'min_samples_split': 17}. Best is trial 77 with value: 0.503116707021326.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:26:12,691]\u001b[0m Trial 93 finished with value: 0.48237437737581834 and parameters: {'n_estimators': 205, 'max_depth': 20, 'min_samples_split': 15}. Best is trial 77 with value: 0.503116707021326.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:26:13,650]\u001b[0m Trial 94 finished with value: 0.4912260211455283 and parameters: {'n_estimators': 192, 'max_depth': 10, 'min_samples_split': 16}. Best is trial 77 with value: 0.503116707021326.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:26:15,241]\u001b[0m Trial 95 finished with value: 0.4862931777117597 and parameters: {'n_estimators': 310, 'max_depth': 12, 'min_samples_split': 17}. Best is trial 77 with value: 0.503116707021326.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:26:16,084]\u001b[0m Trial 96 finished with value: 0.48998555289979046 and parameters: {'n_estimators': 166, 'max_depth': 9, 'min_samples_split': 14}. Best is trial 77 with value: 0.503116707021326.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:26:16,816]\u001b[0m Trial 97 finished with value: 0.4917237171448739 and parameters: {'n_estimators': 136, 'max_depth': 13, 'min_samples_split': 18}. Best is trial 77 with value: 0.503116707021326.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:26:17,975]\u001b[0m Trial 98 finished with value: 0.4863581676450714 and parameters: {'n_estimators': 218, 'max_depth': 10, 'min_samples_split': 15}. Best is trial 77 with value: 0.503116707021326.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:26:18,692]\u001b[0m Trial 99 finished with value: 0.4831964037725083 and parameters: {'n_estimators': 154, 'max_depth': 7, 'min_samples_split': 17}. Best is trial 77 with value: 0.503116707021326.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# creating study\n",
    "study = op.create_study(direction='maximize')\n",
    "# optimising the objective function with the study\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective function 2\n",
    "def objective_2(trial):\n",
    "\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 20)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 1.0)\n",
    "\n",
    "    clf = LGBMClassifier(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate)\n",
    "    return cross_val_score(clf, x_train, np.ravel(y_train), n_jobs=-1, cv=5, scoring=custom_scorer).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-02 16:34:52,069]\u001b[0m A new study created in memory with name: no-name-f73f7a08-9441-4fe1-b3fc-7d75bdf006bf\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:35:04,823]\u001b[0m Trial 0 finished with value: 0.4293571604103116 and parameters: {'n_estimators': 460, 'max_depth': 13, 'learning_rate': 0.2578960794460902}. Best is trial 0 with value: 0.4293571604103116.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:35:08,591]\u001b[0m Trial 1 finished with value: 0.18227648624628012 and parameters: {'n_estimators': 137, 'max_depth': 12, 'learning_rate': 0.5860464252826997}. Best is trial 0 with value: 0.4293571604103116.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:35:10,206]\u001b[0m Trial 2 finished with value: 0.2828150206841702 and parameters: {'n_estimators': 262, 'max_depth': 3, 'learning_rate': 0.5897680381371543}. Best is trial 0 with value: 0.4293571604103116.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:35:14,549]\u001b[0m Trial 3 finished with value: 0.43917889873184757 and parameters: {'n_estimators': 287, 'max_depth': 12, 'learning_rate': 0.35420408570934375}. Best is trial 3 with value: 0.43917889873184757.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:35:19,945]\u001b[0m Trial 4 finished with value: 0.41343486794880613 and parameters: {'n_estimators': 423, 'max_depth': 4, 'learning_rate': 0.373483975435111}. Best is trial 3 with value: 0.43917889873184757.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:35:21,524]\u001b[0m Trial 5 finished with value: 0.1971137035227139 and parameters: {'n_estimators': 365, 'max_depth': 4, 'learning_rate': 0.6165396580455752}. Best is trial 3 with value: 0.43917889873184757.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:35:22,781]\u001b[0m Trial 6 finished with value: 0.15430751803059106 and parameters: {'n_estimators': 288, 'max_depth': 20, 'learning_rate': 0.7890423912793308}. Best is trial 3 with value: 0.43917889873184757.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:35:29,586]\u001b[0m Trial 7 finished with value: 0.4297869446893185 and parameters: {'n_estimators': 287, 'max_depth': 16, 'learning_rate': 0.19352301036496444}. Best is trial 3 with value: 0.43917889873184757.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:35:32,198]\u001b[0m Trial 8 finished with value: 0.20400588556356078 and parameters: {'n_estimators': 347, 'max_depth': 15, 'learning_rate': 0.5172131779318677}. Best is trial 3 with value: 0.43917889873184757.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:35:33,208]\u001b[0m Trial 9 finished with value: 0.47381382898671165 and parameters: {'n_estimators': 262, 'max_depth': 1, 'learning_rate': 0.20842833720236667}. Best is trial 9 with value: 0.47381382898671165.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:35:39,067]\u001b[0m Trial 10 finished with value: 0.4787610277997162 and parameters: {'n_estimators': 154, 'max_depth': 8, 'learning_rate': 0.024056095922175308}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:35:45,663]\u001b[0m Trial 11 finished with value: 0.474736494371579 and parameters: {'n_estimators': 167, 'max_depth': 8, 'learning_rate': 0.010694556810792122}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:35:49,732]\u001b[0m Trial 12 finished with value: 0.4576258208634917 and parameters: {'n_estimators': 114, 'max_depth': 7, 'learning_rate': 0.013464398988924037}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:35:55,986]\u001b[0m Trial 13 finished with value: 0.4539891663952248 and parameters: {'n_estimators': 183, 'max_depth': 8, 'learning_rate': 0.04797189530189942}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:36:01,949]\u001b[0m Trial 14 finished with value: 0.43456485934587497 and parameters: {'n_estimators': 194, 'max_depth': 8, 'learning_rate': 0.09479978910581142}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:36:08,531]\u001b[0m Trial 15 finished with value: 0.4588687591587859 and parameters: {'n_estimators': 195, 'max_depth': 7, 'learning_rate': 0.013770526869559535}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:36:13,398]\u001b[0m Trial 16 finished with value: 0.42891659840680196 and parameters: {'n_estimators': 157, 'max_depth': 10, 'learning_rate': 0.14698334707034044}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:36:16,602]\u001b[0m Trial 17 finished with value: 0.44105880058525526 and parameters: {'n_estimators': 101, 'max_depth': 10, 'learning_rate': 0.29451487585184916}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:36:21,628]\u001b[0m Trial 18 finished with value: 0.4341284658924941 and parameters: {'n_estimators': 226, 'max_depth': 6, 'learning_rate': 0.1384099247463277}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:36:29,620]\u001b[0m Trial 19 finished with value: 0.4369033708120556 and parameters: {'n_estimators': 220, 'max_depth': 17, 'learning_rate': 0.13260419017579816}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:36:32,641]\u001b[0m Trial 20 finished with value: 0.4067065937380726 and parameters: {'n_estimators': 160, 'max_depth': 9, 'learning_rate': 0.403031763869815}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:36:33,967]\u001b[0m Trial 21 finished with value: 0.44641606062180533 and parameters: {'n_estimators': 243, 'max_depth': 2, 'learning_rate': 0.2458646610485374}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:36:35,029]\u001b[0m Trial 22 finished with value: 0.4709236788432024 and parameters: {'n_estimators': 319, 'max_depth': 1, 'learning_rate': 0.08109977902850093}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:36:37,653]\u001b[0m Trial 23 finished with value: 0.45697907528704523 and parameters: {'n_estimators': 140, 'max_depth': 5, 'learning_rate': 0.18710781938169133}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:36:38,971]\u001b[0m Trial 24 finished with value: 0.4695242493354074 and parameters: {'n_estimators': 391, 'max_depth': 1, 'learning_rate': 0.010446894820319602}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:36:43,131]\u001b[0m Trial 25 finished with value: 0.4423529590653196 and parameters: {'n_estimators': 180, 'max_depth': 6, 'learning_rate': 0.10363453351046306}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:36:51,562]\u001b[0m Trial 26 finished with value: 0.43562631086894277 and parameters: {'n_estimators': 499, 'max_depth': 14, 'learning_rate': 0.1723203774520659}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:36:53,838]\u001b[0m Trial 27 finished with value: 0.4703148550187627 and parameters: {'n_estimators': 254, 'max_depth': 3, 'learning_rate': 0.07865404419563392}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:36:59,098]\u001b[0m Trial 28 finished with value: 0.43984659982480406 and parameters: {'n_estimators': 208, 'max_depth': 18, 'learning_rate': 0.22425642607842772}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:37:04,169]\u001b[0m Trial 29 finished with value: 0.4361083565612903 and parameters: {'n_estimators': 322, 'max_depth': 12, 'learning_rate': 0.29272911209295727}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:37:09,227]\u001b[0m Trial 30 finished with value: 0.4555591844569545 and parameters: {'n_estimators': 131, 'max_depth': 11, 'learning_rate': 0.07354016924338054}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:37:10,313]\u001b[0m Trial 31 finished with value: 0.4706725025173203 and parameters: {'n_estimators': 323, 'max_depth': 1, 'learning_rate': 0.08850957894962296}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:37:12,507]\u001b[0m Trial 32 finished with value: 0.4413341282296206 and parameters: {'n_estimators': 402, 'max_depth': 2, 'learning_rate': 0.1722296656854489}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:37:17,177]\u001b[0m Trial 33 finished with value: 0.43996645584733446 and parameters: {'n_estimators': 261, 'max_depth': 5, 'learning_rate': 0.06557152075090482}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:37:19,815]\u001b[0m Trial 34 finished with value: 0.4390354921155758 and parameters: {'n_estimators': 314, 'max_depth': 3, 'learning_rate': 0.2325571031895635}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:37:20,389]\u001b[0m Trial 35 finished with value: 0.46832201872294243 and parameters: {'n_estimators': 158, 'max_depth': 1, 'learning_rate': 0.1443886142591925}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:37:25,127]\u001b[0m Trial 36 finished with value: 0.46879153900583537 and parameters: {'n_estimators': 346, 'max_depth': 4, 'learning_rate': 0.013672783398634702}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:37:36,571]\u001b[0m Trial 37 finished with value: 0.4478139919545324 and parameters: {'n_estimators': 242, 'max_depth': 13, 'learning_rate': 0.10914139932948436}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:37:42,525]\u001b[0m Trial 38 finished with value: 0.43485269860621595 and parameters: {'n_estimators': 450, 'max_depth': 9, 'learning_rate': 0.3096616546038052}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:37:45,859]\u001b[0m Trial 39 finished with value: 0.4350555910017916 and parameters: {'n_estimators': 297, 'max_depth': 3, 'learning_rate': 0.2276115837627014}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:37:53,571]\u001b[0m Trial 40 finished with value: 0.4502388625251605 and parameters: {'n_estimators': 275, 'max_depth': 6, 'learning_rate': 0.04837888841648463}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:37:54,765]\u001b[0m Trial 41 finished with value: 0.4757645229247604 and parameters: {'n_estimators': 319, 'max_depth': 1, 'learning_rate': 0.10494482435684314}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:37:56,973]\u001b[0m Trial 42 finished with value: 0.4502565244088637 and parameters: {'n_estimators': 363, 'max_depth': 2, 'learning_rate': 0.12428168527491257}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:38:00,791]\u001b[0m Trial 43 finished with value: 0.43825036573103915 and parameters: {'n_estimators': 338, 'max_depth': 4, 'learning_rate': 0.187116737579196}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:38:01,731]\u001b[0m Trial 44 finished with value: 0.4682825617042563 and parameters: {'n_estimators': 279, 'max_depth': 1, 'learning_rate': 0.062291151205864065}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:38:08,333]\u001b[0m Trial 45 finished with value: 0.44287287922161644 and parameters: {'n_estimators': 374, 'max_depth': 5, 'learning_rate': 0.04249733878210059}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:38:16,185]\u001b[0m Trial 46 finished with value: 0.4435083173948845 and parameters: {'n_estimators': 307, 'max_depth': 8, 'learning_rate': 0.10033458407532343}. Best is trial 10 with value: 0.4787610277997162.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:38:16,883]\u001b[0m Trial 47 finished with value: 0.48663729230290054 and parameters: {'n_estimators': 124, 'max_depth': 2, 'learning_rate': 0.15389248266233238}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:38:17,505]\u001b[0m Trial 48 finished with value: 0.4698319264616386 and parameters: {'n_estimators': 109, 'max_depth': 2, 'learning_rate': 0.15170592839228456}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:38:20,868]\u001b[0m Trial 49 finished with value: 0.4274301311957269 and parameters: {'n_estimators': 127, 'max_depth': 7, 'learning_rate': 0.1878661919432728}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:38:22,775]\u001b[0m Trial 50 finished with value: 0.41967824889842803 and parameters: {'n_estimators': 174, 'max_depth': 4, 'learning_rate': 0.38501346580852924}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:38:23,459]\u001b[0m Trial 51 finished with value: 0.4783822495967806 and parameters: {'n_estimators': 121, 'max_depth': 2, 'learning_rate': 0.04693808795755028}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:38:24,355]\u001b[0m Trial 52 finished with value: 0.48103302568977285 and parameters: {'n_estimators': 145, 'max_depth': 2, 'learning_rate': 0.040072119004509195}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:38:25,628]\u001b[0m Trial 53 finished with value: 0.47705568755862204 and parameters: {'n_estimators': 121, 'max_depth': 3, 'learning_rate': 0.012170637159582448}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:38:26,897]\u001b[0m Trial 54 finished with value: 0.473782574468159 and parameters: {'n_estimators': 144, 'max_depth': 3, 'learning_rate': 0.034568912543802566}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:38:27,588]\u001b[0m Trial 55 finished with value: 0.46396010459058645 and parameters: {'n_estimators': 124, 'max_depth': 2, 'learning_rate': 0.11660099260269238}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:38:28,844]\u001b[0m Trial 56 finished with value: 0.47374072384949545 and parameters: {'n_estimators': 144, 'max_depth': 3, 'learning_rate': 0.058671741291618305}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:38:29,483]\u001b[0m Trial 57 finished with value: 0.47854494288006205 and parameters: {'n_estimators': 100, 'max_depth': 2, 'learning_rate': 0.04170532192411197}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:38:31,892]\u001b[0m Trial 58 finished with value: 0.4708315638560584 and parameters: {'n_estimators': 106, 'max_depth': 5, 'learning_rate': 0.036447526404291046}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:38:32,797]\u001b[0m Trial 59 finished with value: 0.46106587315085107 and parameters: {'n_estimators': 116, 'max_depth': 2, 'learning_rate': 0.011928557512514669}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:38:34,215]\u001b[0m Trial 60 finished with value: 0.46920243869516287 and parameters: {'n_estimators': 149, 'max_depth': 2, 'learning_rate': 0.147606615498527}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:38:35,756]\u001b[0m Trial 61 finished with value: 0.4657173339751818 and parameters: {'n_estimators': 119, 'max_depth': 3, 'learning_rate': 0.09901190990666993}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:38:36,513]\u001b[0m Trial 62 finished with value: 0.4706368548030759 and parameters: {'n_estimators': 133, 'max_depth': 1, 'learning_rate': 0.04752143534558457}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:38:38,018]\u001b[0m Trial 63 finished with value: 0.4620779446425174 and parameters: {'n_estimators': 101, 'max_depth': 4, 'learning_rate': 0.0827388650165376}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:38:40,133]\u001b[0m Trial 64 finished with value: 0.4424791600892693 and parameters: {'n_estimators': 166, 'max_depth': 4, 'learning_rate': 0.1350799670560414}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:38:40,800]\u001b[0m Trial 65 finished with value: 0.47332606972753466 and parameters: {'n_estimators': 192, 'max_depth': 1, 'learning_rate': 0.07628218226963085}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:38:46,921]\u001b[0m Trial 66 finished with value: 0.4529208823216341 and parameters: {'n_estimators': 153, 'max_depth': 20, 'learning_rate': 0.03357561067735737}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:38:48,204]\u001b[0m Trial 67 finished with value: 0.4570039938900267 and parameters: {'n_estimators': 134, 'max_depth': 3, 'learning_rate': 0.11402768496247764}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:38:48,946]\u001b[0m Trial 68 finished with value: 0.4640293792792269 and parameters: {'n_estimators': 117, 'max_depth': 2, 'learning_rate': 0.17076048063275953}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:38:54,146]\u001b[0m Trial 69 finished with value: 0.4689800882599252 and parameters: {'n_estimators': 177, 'max_depth': 6, 'learning_rate': 0.01106633164542075}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:38:57,574]\u001b[0m Trial 70 finished with value: 0.44271270657316764 and parameters: {'n_estimators': 213, 'max_depth': 5, 'learning_rate': 0.20382951547815037}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:39:03,573]\u001b[0m Trial 71 finished with value: 0.4505079589775722 and parameters: {'n_estimators': 163, 'max_depth': 11, 'learning_rate': 0.07124804213919807}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:39:08,627]\u001b[0m Trial 72 finished with value: 0.4560425788800586 and parameters: {'n_estimators': 140, 'max_depth': 8, 'learning_rate': 0.04748238866966374}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:39:09,377]\u001b[0m Trial 73 finished with value: 0.4767329086282051 and parameters: {'n_estimators': 193, 'max_depth': 1, 'learning_rate': 0.08957734512380253}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:39:10,040]\u001b[0m Trial 74 finished with value: 0.471964998003399 and parameters: {'n_estimators': 193, 'max_depth': 1, 'learning_rate': 0.08817801855766419}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:39:10,678]\u001b[0m Trial 75 finished with value: 0.4716822875856643 and parameters: {'n_estimators': 100, 'max_depth': 2, 'learning_rate': 0.11598330533278114}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:39:11,152]\u001b[0m Trial 76 finished with value: 0.4712893461511095 and parameters: {'n_estimators': 126, 'max_depth': 1, 'learning_rate': 0.160411823545414}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:39:12,592]\u001b[0m Trial 77 finished with value: 0.45327166760930393 and parameters: {'n_estimators': 151, 'max_depth': 3, 'learning_rate': 0.1283393865618109}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:39:14,034]\u001b[0m Trial 78 finished with value: 0.4598104333592383 and parameters: {'n_estimators': 109, 'max_depth': 4, 'learning_rate': 0.06599678699132028}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:39:14,950]\u001b[0m Trial 79 finished with value: 0.4737143568647915 and parameters: {'n_estimators': 168, 'max_depth': 2, 'learning_rate': 0.038538346397506966}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:39:15,452]\u001b[0m Trial 80 finished with value: 0.4733591599049408 and parameters: {'n_estimators': 137, 'max_depth': 1, 'learning_rate': 0.10156033993860487}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:39:21,192]\u001b[0m Trial 81 finished with value: 0.4619826960146707 and parameters: {'n_estimators': 184, 'max_depth': 7, 'learning_rate': 0.030334262658771628}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:39:25,593]\u001b[0m Trial 82 finished with value: 0.4491455457443749 and parameters: {'n_estimators': 122, 'max_depth': 9, 'learning_rate': 0.062121482197574254}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:39:26,712]\u001b[0m Trial 83 finished with value: 0.4739745613101207 and parameters: {'n_estimators': 204, 'max_depth': 2, 'learning_rate': 0.01706501368397186}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:39:34,143]\u001b[0m Trial 84 finished with value: 0.45026639695358633 and parameters: {'n_estimators': 234, 'max_depth': 10, 'learning_rate': 0.08525392949374347}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:39:35,757]\u001b[0m Trial 85 finished with value: 0.4813680568290626 and parameters: {'n_estimators': 158, 'max_depth': 3, 'learning_rate': 0.012238693439052723}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:39:37,080]\u001b[0m Trial 86 finished with value: 0.4674537752871696 and parameters: {'n_estimators': 154, 'max_depth': 3, 'learning_rate': 0.05288100896045285}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:39:37,562]\u001b[0m Trial 87 finished with value: 0.4740918379933592 and parameters: {'n_estimators': 112, 'max_depth': 1, 'learning_rate': 0.14318301010820522}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:39:39,301]\u001b[0m Trial 88 finished with value: 0.46099811006877706 and parameters: {'n_estimators': 130, 'max_depth': 3, 'learning_rate': 0.1018873028906967}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:39:40,442]\u001b[0m Trial 89 finished with value: 0.4777007449051133 and parameters: {'n_estimators': 143, 'max_depth': 2, 'learning_rate': 0.028366327733811966}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:39:43,328]\u001b[0m Trial 90 finished with value: 0.4701867308241729 and parameters: {'n_estimators': 147, 'max_depth': 4, 'learning_rate': 0.02528907111053708}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:39:44,346]\u001b[0m Trial 91 finished with value: 0.47504839855188097 and parameters: {'n_estimators': 170, 'max_depth': 2, 'learning_rate': 0.06099515002673031}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:39:44,905]\u001b[0m Trial 92 finished with value: 0.46371263184194333 and parameters: {'n_estimators': 138, 'max_depth': 1, 'learning_rate': 0.0343747226471258}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:39:45,769]\u001b[0m Trial 93 finished with value: 0.4767173682516204 and parameters: {'n_estimators': 157, 'max_depth': 2, 'learning_rate': 0.08790090010641588}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:39:47,125]\u001b[0m Trial 94 finished with value: 0.46869845199763427 and parameters: {'n_estimators': 160, 'max_depth': 3, 'learning_rate': 0.08084117964686015}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:39:48,239]\u001b[0m Trial 95 finished with value: 0.47101161580456347 and parameters: {'n_estimators': 183, 'max_depth': 2, 'learning_rate': 0.05185054223087609}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:39:50,247]\u001b[0m Trial 96 finished with value: 0.4658429524840081 and parameters: {'n_estimators': 121, 'max_depth': 4, 'learning_rate': 0.011978315902515357}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:39:51,474]\u001b[0m Trial 97 finished with value: 0.48029310066883324 and parameters: {'n_estimators': 143, 'max_depth': 3, 'learning_rate': 0.08584779967558119}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:39:52,448]\u001b[0m Trial 98 finished with value: 0.4817654096050644 and parameters: {'n_estimators': 108, 'max_depth': 3, 'learning_rate': 0.0354216069201202}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:39:54,657]\u001b[0m Trial 99 finished with value: 0.44761370715364174 and parameters: {'n_estimators': 110, 'max_depth': 5, 'learning_rate': 0.12839617913523657}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:39:59,784]\u001b[0m Trial 100 finished with value: 0.46810998205168025 and parameters: {'n_estimators': 130, 'max_depth': 15, 'learning_rate': 0.029675140810257808}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:40:00,709]\u001b[0m Trial 101 finished with value: 0.46240939693428285 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.0643475822455045}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:40:02,813]\u001b[0m Trial 102 finished with value: 0.4648179799358223 and parameters: {'n_estimators': 144, 'max_depth': 4, 'learning_rate': 0.037218723595188}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:40:03,919]\u001b[0m Trial 103 finished with value: 0.4813881388526209 and parameters: {'n_estimators': 118, 'max_depth': 3, 'learning_rate': 0.013321882110558587}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:40:04,989]\u001b[0m Trial 104 finished with value: 0.48591083717450545 and parameters: {'n_estimators': 116, 'max_depth': 3, 'learning_rate': 0.025622446363194655}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:40:05,702]\u001b[0m Trial 105 finished with value: 0.4750843326111319 and parameters: {'n_estimators': 112, 'max_depth': 2, 'learning_rate': 0.05236025139522586}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:40:06,861]\u001b[0m Trial 106 finished with value: 0.4819033587341065 and parameters: {'n_estimators': 127, 'max_depth': 3, 'learning_rate': 0.026529763187724154}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:40:09,946]\u001b[0m Trial 107 finished with value: 0.4548838842496262 and parameters: {'n_estimators': 117, 'max_depth': 5, 'learning_rate': 0.010276818008638916}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:40:11,180]\u001b[0m Trial 108 finished with value: 0.4714507741146046 and parameters: {'n_estimators': 128, 'max_depth': 3, 'learning_rate': 0.0749512574015172}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:40:12,689]\u001b[0m Trial 109 finished with value: 0.4575933153634062 and parameters: {'n_estimators': 106, 'max_depth': 4, 'learning_rate': 0.1155225053997861}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:40:13,882]\u001b[0m Trial 110 finished with value: 0.47234114300493957 and parameters: {'n_estimators': 136, 'max_depth': 3, 'learning_rate': 0.05421707783823558}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:40:15,169]\u001b[0m Trial 111 finished with value: 0.4732711284720553 and parameters: {'n_estimators': 146, 'max_depth': 3, 'learning_rate': 0.02990209710271797}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:40:15,881]\u001b[0m Trial 112 finished with value: 0.47634315546337913 and parameters: {'n_estimators': 126, 'max_depth': 2, 'learning_rate': 0.0439593103861735}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:40:19,653]\u001b[0m Trial 113 finished with value: 0.46824770422962825 and parameters: {'n_estimators': 135, 'max_depth': 6, 'learning_rate': 0.026002723425083092}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:40:20,320]\u001b[0m Trial 114 finished with value: 0.47699612036242006 and parameters: {'n_estimators': 117, 'max_depth': 2, 'learning_rate': 0.07085236538109581}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:40:21,699]\u001b[0m Trial 115 finished with value: 0.48021286815117925 and parameters: {'n_estimators': 106, 'max_depth': 4, 'learning_rate': 0.0984537464600744}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:40:22,667]\u001b[0m Trial 116 finished with value: 0.47496079077468367 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1058269141613283}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:40:24,048]\u001b[0m Trial 117 finished with value: 0.45846692493278496 and parameters: {'n_estimators': 107, 'max_depth': 4, 'learning_rate': 0.15834371570523886}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:40:25,615]\u001b[0m Trial 118 finished with value: 0.4625345812273295 and parameters: {'n_estimators': 121, 'max_depth': 4, 'learning_rate': 0.09018196985874899}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:40:27,271]\u001b[0m Trial 119 finished with value: 0.46673054642166995 and parameters: {'n_estimators': 112, 'max_depth': 4, 'learning_rate': 0.11929662469649643}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:40:28,584]\u001b[0m Trial 120 finished with value: 0.4512140284446728 and parameters: {'n_estimators': 153, 'max_depth': 3, 'learning_rate': 0.1373050118172604}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:40:29,484]\u001b[0m Trial 121 finished with value: 0.46193666403796774 and parameters: {'n_estimators': 140, 'max_depth': 2, 'learning_rate': 0.010012942061238844}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:40:30,209]\u001b[0m Trial 122 finished with value: 0.47559159280334207 and parameters: {'n_estimators': 131, 'max_depth': 2, 'learning_rate': 0.04796459616795244}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[32m[I 2023-02-02 16:40:34,433]\u001b[0m Trial 123 finished with value: 0.4578075240403242 and parameters: {'n_estimators': 163, 'max_depth': 5, 'learning_rate': 0.06746557162852612}. Best is trial 47 with value: 0.48663729230290054.\u001b[0m\n",
      "\u001b[33m[W 2023-02-02 16:40:36,167]\u001b[0m Trial 124 failed with parameters: {'n_estimators': 125, 'max_depth': 3, 'learning_rate': 0.03670272216983782} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kshit\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\kshit\\AppData\\Local\\Temp\\ipykernel_13072\\677624887.py\", line 8, in objective_2\n",
      "    return cross_val_score(clf, x_train, np.ravel(y_train), n_jobs=-1, cv=5, scoring=custom_scorer).mean()\n",
      "  File \"c:\\Users\\kshit\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 515, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "  File \"c:\\Users\\kshit\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 266, in cross_validate\n",
      "    results = parallel(\n",
      "  File \"c:\\Users\\kshit\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\joblib\\parallel.py\", line 1061, in __call__\n",
      "    self.retrieve()\n",
      "  File \"c:\\Users\\kshit\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\joblib\\parallel.py\", line 938, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"c:\\Users\\kshit\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"c:\\Users\\kshit\\anaconda3\\envs\\machine_learning\\lib\\concurrent\\futures\\_base.py\", line 453, in result\n",
      "    self._condition.wait(timeout)\n",
      "  File \"c:\\Users\\kshit\\anaconda3\\envs\\machine_learning\\lib\\threading.py\", line 320, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\u001b[33m[W 2023-02-02 16:40:36,169]\u001b[0m Trial 124 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m study \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective_2, n_trials\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\kshit\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\optuna\\study\\study.py:425\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    322\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    323\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    330\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    332\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \n\u001b[0;32m    334\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    423\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 425\u001b[0m     _optimize(\n\u001b[0;32m    426\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    427\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    428\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    429\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    430\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    431\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[0;32m    432\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    433\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    434\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    435\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kshit\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\kshit\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\kshit\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\kshit\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[88], line 8\u001b[0m, in \u001b[0;36mobjective_2\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m      5\u001b[0m learning_rate \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39msuggest_float(\u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0.01\u001b[39m, \u001b[39m1.0\u001b[39m)\n\u001b[0;32m      7\u001b[0m clf \u001b[39m=\u001b[39m LGBMClassifier(n_estimators\u001b[39m=\u001b[39mn_estimators, max_depth\u001b[39m=\u001b[39mmax_depth, learning_rate\u001b[39m=\u001b[39mlearning_rate)\n\u001b[1;32m----> 8\u001b[0m \u001b[39mreturn\u001b[39;00m cross_val_score(clf, x_train, np\u001b[39m.\u001b[39;49mravel(y_train), n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, cv\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, scoring\u001b[39m=\u001b[39;49mcustom_scorer)\u001b[39m.\u001b[39mmean()\n",
      "File \u001b[1;32mc:\\Users\\kshit\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    527\u001b[0m )\n\u001b[0;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\kshit\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[0;32m    269\u001b[0m         X,\n\u001b[0;32m    270\u001b[0m         y,\n\u001b[0;32m    271\u001b[0m         scorers,\n\u001b[0;32m    272\u001b[0m         train,\n\u001b[0;32m    273\u001b[0m         test,\n\u001b[0;32m    274\u001b[0m         verbose,\n\u001b[0;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    276\u001b[0m         fit_params,\n\u001b[0;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[0;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[0;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    281\u001b[0m     )\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kshit\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\joblib\\parallel.py:1061\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1061\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1062\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\kshit\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\joblib\\parallel.py:938\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    936\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 938\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    939\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    940\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\kshit\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    543\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kshit\\anaconda3\\envs\\machine_learning\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\kshit\\anaconda3\\envs\\machine_learning\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# study 2\n",
    "study = op.create_study(direction='maximize')\n",
    "study.optimize(objective_2, n_trials=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e9e12bc012fae32ac9654bb37cb31a0d4c91164effa766e52fa90ec4ccf2e77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
